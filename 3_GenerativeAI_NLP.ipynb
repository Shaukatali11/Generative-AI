{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Remove URLs**\n",
        "\n",
        "**Definition:** URLs are often irrelevant for analysis, so we remove them to focus on the main content. This is especially helpful in social media and review data.\n",
        "\n",
        "**When to Use:** Use this when text data includes links that don‚Äôt contribute to the meaning (e.g., review comments, tweets)."
      ],
      "metadata": {
        "id": "5RKrwJ7_fCXr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYEkSgi_dit4",
        "outputId": "3f9467ce-7985-4b9f-b9ad-11984170e166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heyyyy!!! This is gr8 ü§©, visit  for more info!! LOL üòÇ. Thnx in advnce.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def remove_urls(text):\n",
        "    # Regular expression pattern to match URLs\n",
        "    url_pattern = r'http\\S+|www\\S+'\n",
        "    cleaned_text = re.sub(url_pattern, '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "# Example usage\n",
        "text = \"Heyyyy!!! This is gr8 ü§©, visit https://example.com for more info!! LOL üòÇ. Thnx in advnce.\"\n",
        "print(remove_urls(text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Handle Punctuation**\n",
        "\n",
        "**Definition**: Punctuation marks like ‚Äú!‚Äù and ‚Äú?‚Äù can affect text analysis. We can choose to either remove them entirely or replace them with spaces.\n",
        "\n",
        "**When to Use**: This is useful when punctuation doesn‚Äôt add significant meaning or when we want to standardize the input text."
      ],
      "metadata": {
        "id": "xYX5dIwIfZWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    # Use string.punctuation to remove all punctuation characters\n",
        "    cleaned_text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    return cleaned_text\n",
        "\n",
        "# Example usage\n",
        "text = \"Heyyyy!!! This is gr8 ü§©, visit example.com for more info!! LOL üòÇ. Thnx in advnce.\"\n",
        "print(remove_punctuation(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH-Z8AhDfPsG",
        "outputId": "768dd56a-2f05-4101-ddcb-0845bc48df8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heyyyy This is gr8 ü§© visit examplecom for more info LOL üòÇ Thnx in advnce\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Expand Chat Abbreviations**\n",
        "\n",
        "**Definition**: Chat abbreviations like ‚Äúgr8‚Äù (great) and ‚ÄúLOL‚Äù (laughing out loud) are expanded to their full forms. This step is essential for readability and for models to understand meaning.\n",
        "\n",
        "**When to Use**: Use this when analyzing informal or social media text where abbreviations are common."
      ],
      "metadata": {
        "id": "U5Mo_KuEfoYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_abbreviations(text):\n",
        "    # Define a dictionary of common chat abbreviations and their expansions\n",
        "    abbreviations = {\n",
        "        \"gr8\": \"great\",\n",
        "        \"LOL\": \"laughing out loud\",\n",
        "        \"Thnx\": \"thanks\",\n",
        "        \"advnce\": \"advance\"\n",
        "    }\n",
        "    # Replace abbreviations with their full forms\n",
        "    words = text.split()\n",
        "    expanded_words = [abbreviations[word] if word in abbreviations else word for word in words]\n",
        "    return ' '.join(expanded_words)\n",
        "\n",
        "# Example usage\n",
        "text = \"Heyyyy!!! This is gr8 ü§©, visit example.com for more info!! LOL üòÇ. Thnx in advnce.\"\n",
        "print(expand_abbreviations(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBgEzSOofiJC",
        "outputId": "5b693dd6-1b84-4dab-c5a8-d51db0dad063"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heyyyy!!! This is great ü§©, visit example.com for more info!! laughing out loud üòÇ. thanks in advnce.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Tokenization and Stemming**\n",
        "\n",
        "**Tokenization:** Breaking down text into smaller pieces, typically words, called tokens.\n",
        "\n",
        "**Stemming:** Reducing words to their root forms to standardize them.\n",
        "When to Use: Tokenization and stemming are core preprocessing steps in NLP for text normalization and to simplify model vocabulary"
      ],
      "metadata": {
        "id": "BSD5p3HEf338"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "def tokenize_and_stem(text):\n",
        "    # Tokenize the text into words\n",
        "    tokens = word_tokenize(text)\n",
        "    # Initialize the stemmer\n",
        "    stemmer = PorterStemmer()\n",
        "    # Apply stemming to each token\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "    return stemmed_tokens\n",
        "\n",
        "# Example usage\n",
        "text = \"Heyyyy!!! This is gr8 ü§©, visit example.com for more info!! LOL üòÇ. Thnx in advnce.\"\n",
        "print(tokenize_and_stem(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feTufQAVfwbG",
        "outputId": "c25e6400-dd50-4610-f3b1-1a6b7bde9804"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['heyyyi', '!', '!', '!', 'thi', 'is', 'gr8', 'ü§©', ',', 'visit', 'example.com', 'for', 'more', 'info', '!', '!', 'lol', 'üòÇ', '.', 'thnx', 'in', 'advnc', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Handle Incorrect Spelling**\n",
        "\n",
        "**Definition:** Corrects misspelled words to improve the quality of text analysis. This step ensures more accurate data and can help avoid vocabulary mismatches.\n",
        "\n",
        "**When to Use:** Use this in cases with frequent spelling errors, such as social media text or informal messages."
      ],
      "metadata": {
        "id": "ZYCzpju0gGAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker\n",
        "!pip install emoji\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m-yZNsFgQfV",
        "outputId": "eb68a21a-bbe7-444e-8f7f-359b3c7cdd2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.1\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "def correct_spelling(text):\n",
        "    # Initialize spell checker\n",
        "    spell = SpellChecker()\n",
        "    words = text.split()\n",
        "    # Check each word and correct it if misspelled\n",
        "    corrected_words = [spell.correction(word) if word in spell else word for word in words]\n",
        "    return ' '.join(corrected_words)\n",
        "\n",
        "# Example usage\n",
        "text = \"Heyyyy!!! This is gr8 ü§©, visit example.com for more info!! LOL üòÇ. Thnx in advnce.\"\n",
        "print(correct_spelling(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM9xdNy2gB6M",
        "outputId": "55ae21ca-b079-444c-82e0-e05cd3eaa771"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heyyyy!!! This is gr8 ü§©, visit example.com for more info!! LOL üòÇ. Thnx in advnce.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Handle Emojis**\n",
        "\n",
        "**Definition:** Emojis are commonly used in social media and casual texts. You can either remove them or replace them with descriptive text to capture their sentiment.\n",
        "\n",
        "**When to Use:** Use this for datasets containing social media posts, reviews, or any informal texts where emojis convey important context or sentiment."
      ],
      "metadata": {
        "id": "OCyN4VbggTt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "\n",
        "def handle_emojis(text):\n",
        "    # Translate emojis to descriptive text\n",
        "    return emoji.demojize(text)\n",
        "\n",
        "# Example usage\n",
        "text = \"Heyyyy!!! This is gr8 ü§©, visit example.com for more info!! LOL üòÇ. Thnx in advnce.\"\n",
        "print(handle_emojis(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drm-a3cDgODk",
        "outputId": "ec5ebf4b-b978-414f-9f27-0e80c6dec711"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heyyyy!!! This is gr8 :star-struck:, visit example.com for more info!! LOL :face_with_tears_of_joy:. Thnx in advnce.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Putting It All Together**\n"
      ],
      "metadata": {
        "id": "wbaQLNmrggmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Step 1: Remove URLs\n",
        "    text = remove_urls(text)\n",
        "    # Step 2: Remove punctuation\n",
        "    text = remove_punctuation(text)\n",
        "    # Step 3: Expand chat abbreviations\n",
        "    text = expand_abbreviations(text)\n",
        "    # Step 4: Tokenize and stem\n",
        "    text = ' '.join(tokenize_and_stem(text))\n",
        "    # Step 5: Correct spelling\n",
        "    text = correct_spelling(text)\n",
        "    # Step 6: Handle emojis\n",
        "    text = handle_emojis(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "text = \"Heyyyy!!! This is gr8 ü§©, visit https://example.com for more info!! LOL üòÇ. Thnx in advnce.\"\n",
        "print(preprocess_text(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "witfcSF2gZ9L",
        "outputId": "122a59fd-3cbe-4b50-c1a1-25b68a8f8c8e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heyyyi thi is great :star-struck: visit for more info laugh out loud :face_with_tears_of_joy: thank in advanc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x8aaY41Vg3qh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}